---
description: >-
  네트워크가 끊기거나, 타이밍 이슈 등을 어떻게 회피할 수 있을까? 또, 종잡을 수 없는 분산 시스템의 상태를 무슨 일이 일어났던 것인지
  어떻게 추론할 수 있을까.
---

# 8. 분산 시스템의 골칫거리

## 결함과 부분 장애

분산 시스템을 다루기 어려운 이유는 부분 장애와 비결정성 때문이다.

시스템의 어떤 부분은 잘 동작하지만 다른 부분이 예측할 수 없는 방식으로 고장나는 걸 **부분 장애(partial failure)**라고 하고, 이러한 부분 장애는 비결정적이다. 즉, 100번 실행했을 때 100번 다 똑같은 결과를 반환하는 걸 보장하지 않는다.

### 클라우드 컴퓨팅과 슈퍼컴퓨팅

슈퍼컴퓨팅은 흔히 부분 장애가 발생하면 전체 장애로 확산시켜 클러스터 자체를 중단시켜 버린다(마치 단일 장비의 커널 패닉처럼). 그러나 클라우드 컴퓨팅은 그런 짓을 했다가는 모가지가 날아가기 때문에, 언제든 부분 장애가 발생할 수 있다는 가능성을 받아들이고 시스템 안에 내결함성을 위한 메커니즘을 잘 녹여내야 한다.

클라우드 컴퓨팅을 구축할 때 만큼은 의심, 비관, 편집증이 빛을 발한다. 우리는 **신뢰성이 없는 구성요소들로 신뢰성이 있는 시스템을 만들어야 하기 때문**이다.

## 신뢰성 없는 네트워크

분산 시스템에서 각 노드들에게 네트워크는 서로가 통신하는 유일한 수단이다. 그러나 네트워크는 신뢰성이 없다. 다른 노드로 요청을 보내서 응답을 받지 못했다면 정확히 그 이유를 아는 것은 불가능하기 때문이다.

1. 요청이 손실되었는지 알 수 없다.
2. 원격 노드가 다운되었는지 알 수 없다.
3. 응답이 손실되었는지 알 수 없다.

흔히 타임아웃으로 이 문제를 해결하고자 하지만, 원격 노드가 응답을 받았는지 아닌지는 여전히 알 수 없다.

### 현실의 네트워크 결함

네트워크 결함은 언제든지 발생할 수 있으므로 소프트웨어가 이를 잘 처리할 수 있게 해야 한다. 우리는 네트워크 문제에 소프트웨어가 어떻게 반응하는지 알아야 하고, 신뢰성 높은 시스템을 만들기 위해 고의로 네트워크 문제를 유발시켜 시스템 반응을 테스트를 해보는 것도 나쁘지 않은 선택이다.

### 결함 감지

분산 시스템에서 결함이 있는 노드를 자동으로 감지할 수 있어야 한다.

* 로드 벨런서가 죽은 노드로 요청을 그만 보내야 한다.
* Master가 장애나면 Slave가 Master로 승격되어야 한다.

그러나 네트워크가 간직한 불확실성 때문에 노드가 동작 중인지 구별하기 어렵다.

따라서 보통은 죽었거나 죽어가는 노드로부터 결함 있음을 전달받는 걸 기대하기 보다, 응답 받지 못하는 경우를 장애가 난 것으로 판단한다(재시도와 타임아웃을 곁들여서).

### 타임아웃과 기약 없는 지연

타임아웃은 너무 짧거나 길면 문제가 된다.

타임아웃이 너무 길면:

* 사용자는 오랫동안 기다리거나 오류메시지를 봐야 한다.

타임아웃이 너무 짧으면:

* 노드가 실제로는 살아있는데 다른 노드에게 동작이 위임되면서 2번 실행된다.
* 부하로 인해 느려진 노드를 죽었다고 판단하면 다른 노드들에 그 부하가 가중된다.

사실 완벽한 타임아웃 시간을 정하려면 네트워크 최대 지연시간 \* 2(왕복) + 시스템의 처리 시간으로 구해야 하지만, 비동기 네트워크의 경우 기약 없는 지연(unbounded delay)이 있고 대부분의 시스템은 정해진 최대 시간 내에 요청을 처리한다고 보장할 수 없다.

결국 실험적으로 타임아웃을 결정해야 한다.

* 네트워크 응답 시간의 분포를 계산하여 적절한 타임아웃을 구한다.
* 시스템이 자동으로 응답 시간과 변동성(jitter)을 측정하고 타임아웃을 조절하게 한다.

## 신뢰성 없는 시계

분산 시스템에서 각 노드는 각자 자신의 시계(실제 하드웨어 - quartz crystal oscillator)를 갖고 있다. 이 시계는 불행히도 완벽히 정확하지는 않아서, 각 노드마다 시간이 빠르거나 느릴 수 있다. 각 시스템의 시간이 서로 다르면 메트릭을 뽑아내는데 큰 어려움이 생기므로, NTP(Network Time Protocol)로 서버 그룹에서 GPS 수신자 같은 정확한 시간 출처로부터 시각을 얻어내 각 노드의 시계를 조정해준다.

### 단조 시계 대 일 기준 시계

현대 컴퓨터는 최소 2가지 종류의 시계를 갖고 있다.

* 일 기준 시계(time-of-day clock): 실제 시계처럼 시각을 확인하는 데 쓰임, NTP로 동기화 한다.
* 단조 시계(monotonic clock): 타임아웃이나 응답 시간을 재는 데 쓰임.

{% hint style="info" %}
일 기준 시계에 해당하는 리눅스의 clock\_gettime(CLOCK\_REALTIME) 이나 java의 System.currentTimeMillis() 는 윤초를 세지 않는다.
{% endhint %}

### 시계 동기화와 정확도

NTP로 시계 동기화를 시킨다 한들, 최소한 네트워크 지연만큼의 시간오차가 발생하므로 정확하게 시각을 아는 것은 불가능하다.

또, 윤초가 발생하면 1분의 길이 59초나 61초가 되어 많은 대형 시스템을 고장냈던 이력도 있다. 보통 윤초를 조정하기 위해 1초를 하루 동안 서서히 밀리거나 빠르게 흐르도록 NTP 가 거짓말을 하도록 만드는데, 이를 문지름(smearing)이라고 부른다.

### 동기화된 시계에 의존하기

동기화된 시계에 의존하는 게 위험한 상황을 만들 수 있다.

분산 시스템에 충돌 해소를 위해 흔히 쓰이는 전략인 LWW(Last write wins)는 다중 리더 복제와 카산드라와 같은 리더가 없는 데이터베이스에서 널리 사용된다. 이 전략은 충돌이 발생하는 경우 timestamp가 큰 이벤트의 손을 들어주는데, 노드 간 시간이 다르게 흐른다면 의도했던 대로 전략이 수행되지 않을 수 있다.

위와 같은 상황을 회피하기 위해 이벤트 처리에 LWW 전략을 사용하기 위해서는 단조 증가하는 event ID를 이용하는 것이 합리적인 대안이다.

그러나 여러 데이터 센터에 여러 노드가 분산돼 있을 때는 모든 파티션에 걸쳐서 단조 증가하는 ID를 생성하기 어렵다.특히 트랜젝션의 영역으로 가게되면 더 그렇다.

A 트랜잭션이 쓴 값을 B 트랜잭션이 읽는다면 B 트랜잭션의 ID가 A 트랜잭션 ID보다 항상 크다는 것이 보장되어야 하는데 이러한 작고 빠른 트랜잭션이 많으면 ID 생성부터가 엄청난 병목을 떠안게 된다.

> 트위터의 snowflake 는 거의(Approximately) 단조 증가하는 분산 일련번호를 생성하기도 하나, '거의' 라는 수식어에서 알 수 있듯이 인과적 일관성을 보장하지 못한다.

Spanner에서는 시계 신뢰구간을 이용하여 인과성을 반영한다. 시계 신뢰구간은 조회 하면 \[from \~ to]의 시간 구간을 던지는데, 조회 시각이 범위 안에 포함되는 것이 보장된다. A 트랜잭션의 신뢰구간의 범위가 B 트랜잭션의 신뢰구간의 범위보다 과거라면 A 다음에 B가 일어났다는 것을 보장할 수 있고, 신뢰구간이 곂치는 것을 방지하기 위해 의도적으로 신뢰구간의 길이만큼 트랜잭션의 커밋 전에 기다린다.

### 프로세스 중단

시계에 의존하는 것이 위험할 수도 있는 다른 예시를 살펴보자.

Master - Slave 파티셔닝에서, Master 가 요청을 받은 시점부터 10초 이내면 Master를 유지하고, 처리를 못하는 시간이 10초를 넘어가면 Slave를 Master로 승격시키는 상황을 생각했을 때 아래 코드를 떠올려 볼 수 있다.

```
whilte (true) {
    request = getIncomingRequest();
    if (lease.expiryTimeMillis - System.currentTimeMillis() < 100000) {
        lease = lease.renew();
    }

    if (lease.isValid()) {
        process(request);
    }
}
```

위 코드는 잘못된 가정을 했다.

* 동기화된 시계에 의존하고, 그 시계에 정확하다고 믿고 있다.
* `System.currentTimeMillis()` 와 `process(request)`사이에 매우 짧은 시간이 흐른다고 가정한다.
  * 처리 시간이 10초를 넘겨버리면, Slave가 Master로 승격되면서 안정하지 않은 연산(중복 실행 등)이 실행될 수도 있다.

특히 처리 시간이 짧을 것이라고 가정하는 것이 위험한 것이, 하기와 같은 이유에서다.

* 여러 프로그래밍에서 런타임에 발생하는 Stop-the-world GC 중단은 심지어 몇 분 동안이나 지속될 수 있다.
* 가상 환경에서 노드가 Suspend(모든 프로세스 실행을 멈추고 디스크에 메모리 내용 저장) & Resume(메모리 내용을 복원하고 프로세스 재개)이 프로세스 실행 중 언제라도 발생할 수 있다.
* 운영체제에서 컨텍스트 스위칭하는 경우 현재 실행 중인 스레드가 코드 임의 지점에서 멈출 수 있다.
* 메모리가 디스크로도 스왑(페이징)될 수 있도록 운영체제라면, 이 매우 느린 I/O가 실행되는 동안 스레드가 멈춘다.

단일 장비에서야 뮤텍스, 세마포어, 아토믹 연산, lock-free 자료구조, 블로킹 큐를 통해 신뢰성있게 다중 스레드를 실행시킬 수 있다. 하지만 분산 환경이라면 어느 시점에 상당한 시간동안 멈출 수 있다고 가정해야 한다.

그러나 그러한 가정이 따른다고 하더라도,

* GC가 너무 많은 일을 하지 않도록 보장(잘 짜여진 코드를 통해)
* GC 중단이 발생하는 경우 다른 노드가 트래픽을 대신 받도록 인프라 구축
* API 최대 응답 시간 문서화

와 같은 노력을 통해 시스템의 신뢰성을 높여야 한다.

## 지식, 진실, 그리고 거짓말

분산 시스템에서는 장애가 생겼을 때 네트워크의 문제인지 노드 자체의 문제인지 조차 확실히 알 수 없다. 그러나 시스템의 동작에 대해 정한 가정들을 만족시키면서 신뢰성 있는 시스템을 구축할 수 있다.

### 진실은 다수결로 결정된다

여러 분산 알고리즘은 노드들 사이의 투표에 의존하여 진실을 결정한다. 실제로 노드가 살아 있더라도, 과반수 이상의 노드가 해당 노드가 장애가 났다고 판단하면 그 노드는 결정에 따라 물러나야 한다.

그러나 해당 노드가 정상적인 것처럼 그대로 동작하게 되면 다음과 같이 데이터 오염이 발생할 수 있다.

1. 노드 1이 요청을 받아 처리하다 GC stop-the-world 를 만나 중단된다.
2. Lock Service 가 노드 1을 장애로 판단, 노드 2를 리더로 선출하여 잠금을 획득하게 한다.
3. 노드 2가 대신 요청을 받아 위 작업을 이어 받아 처리한다(데이터 삽입).
4. 노드 1이 재개하여 기존 작업을 하다 데이터 충돌이 발생한다.

위 상황을 방어하기 위한 가장 간단한 기법으로는 펜싱(fencing) 토큰이 있다. 이름 그대로 시스템 동작에 울타리를 치는 것이다.

1. 노드 1이 요청을 받아 처리하다 GC stop-the-world 를 만나 중단된다. 토큰 = 33.
2. Lock Service 가 노드 1을 장애로 판단, 토큰을 1 증가시키고 노드 2를 리더로 선출하여 잠금을 획득하게 한다.
3. 리더로 선출된 노드 2가 대신 요청을 받아 위 작업을 그대로 처리한다(데이터 삽입). 토큰 = 34.
4. 노드 1이 재개하여 기존 작업을 하지만, 토큰이 만료되었으므로 작업이 거부된다.

{% hint style="info" %}
Lock Service 로 zookeeper 를 사용하면 트랜잭션 ID나 노드 버전 같은 걸 펜싱 토큰으로 사용할 수 있다. 이 값들은 단조 증가가 보장된다.
{% endhint %}

### 비잔틴 결함

비잔틴 결함은 신뢰성 없는 노드들이 서로 진실을 말한다는 가정이 깨졌을 때 발생한다. 예를 들면 어떤 노드가 받지도 않은 요청을 받았다고 주장하는 경우다. 이런 신뢰할 수 없는 환경에서 합의에 도달하는 문제를 비잔틴 장군 문제(Byzantine Generals Problem)라고 한다.

비잔틴 결함은 클라이언트의 악성 공격이나 소프트웨어 버그로 발생할 수 있다. 비잔틴 내결함성(Byzantine fault-tolerant)을 끌어올리기 위해 우리는 다음과 같은 액션 아이템을 취할 수 있다.

* 애플리케이션 수준 프로토콜에서 체크섬을 통해 무결성을 검증한다.
* 사용자의 입력을 신중하게 살균(sanitize)한다.
* NTP 서버를 여러 대를 써서 올바른 시간을 정할 때 다수결을 하도록 한다.

\
