---
description: >-
  데이터베이스가 저장과 검색을 내부적으로 처리하는 방법을 이 장에서 알아본다. 이걸 알아야 하는 이유는, 특정 Workload(작업 부하)
  유형에서 좋은 성능을 내게끔 저장소 엔진을 조정하려면 저장소 엔진이 내부에서 수행되는 작업에 대해 대략적인 개념을 이해할 필요가 있기
  때문이다. 특히 트랜잭션에 최적화된 저장소 엔진과 분석을 위해 최적화된 엔진은 크게 다
---

# 3장. 저장소와 검색

## 데이터베이스를 강력하게 만드는 데이터 구조

아주 단순하게 데이터베이스를 구현했다고 했을 때, 원하는 값을 찾으려면 O(n)의 시간복잡도가 걸릴 것이다. O(n)은 구리니까, 똑똑한 엔지니어들이 고민하다 색인(index)이라는 걸 만들어 냈다.

색인은 기본적으로 어떤 부가적인 메타데이터를 유지하며, 이를 이정표 삼아 데이터의 위치를 빠르게 찾을 수 있도록 도와준다. 그러나 여기에는 트레이드 오프가 따른다.

* 색인이 잘 설계되었다면 읽기가 빨라진다.
* 색인이 많아지면 쓰기가 느려진다.

따라서 일반적으로 DB는 모든 컬럼에 색인을 걸지 않기 때문에 개발자들이 수동적으로 어떻게 색인을 걸지 선택해야 한다.

### 해시 색인

Bitcask는 인메모리 해시 맵을 만들어서 색인을 한다. 이런 저장소는 각 키의 값이 자주 갱신되는 상황(e.g. 고양이 동영상 링크의 재생 횟수)에 적합하다. 인메모리라고 해서 메모리 안에서만 데이터를 저장하는 것은 아니고, 데이터 파일에 데이터를 저장하고 메모리에 로딩한다. 그렇지 않으면 데이터베이스 재시작시에 모든 데이터가 날아가기 때문이다.

고양이 동영상이 재생될 때마다 데이터 파일에 로그가 쌓일 것이기 때문에 언젠가는 디스크가 모자라는 상황에 도달한다. 이를 막기 위해 보통 세그먼트 파일을 만들어서, 스냅샷을 디스크에 저장한다. 스냅샷을 만드는 과정을 컴팩션(compaction)이라고 하며, 병합된 후에는 예전 세그먼트 파일을 삭제할 수 있다.

이러니 저러니해도 해시 테이블 색인은 제한 사항이 있다.

* 키가 너무 많으면 문제가 된다. 해시 충돌 문제며, 메모리 용량 제한 문제 등을 해결해야 한다.
* 키 기반 Range query 에 효율적이지 못하다. 범위로 검색하려면 모든 개별 키를 조회해야 한다.

### SS테이블과 LSM 트리

SS테이블(Sorted String Table)은 인 메모리 해시 색인의 각 키들이 정렬된 형태라고 보면 된다. 간단히 키로 정렬한 것 만으로도 해시 테이블의 제한을 없앴다.

* 키가 정렬되어 있어 mergesort와 유사하게 병합이 가능해지고, 따라서 컴팩션 성능이 좋아진다.
* 모든 키의 색인을 유지하지 않고, sparse index를 유지할 수 있다. 조회하려는 키가 없는 경우, sparse index의 가장 가까운 key에서부터 스캔하면 된다.
* sparse index를 쓰게 되면 index 사이 사이의 데이터들을 압축해 세그먼트 블록을 만들 수 있다. 이것은 디스크 공간을 절약할 뿐만 아니라 I/O 대역폭 사용도 줄인다.

데이터를 키로 정렬하려면 어떻게 해야 할까? 다음과 같이 balanced tree(레드 블랙 트리나 AVL 트리)를 이용해 임의로 키를 삽입하고 정렬된 순서로 해당 키를 읽을 수 있다.

* 쓰기가 들어오면 balanced tree 데이터 구조(memtable이라고 부르기도 한다)에 추가한다.
* tree 사이즈가 일정한 값보다 커지면 SS테이블 파일(세그먼트 파일)로 디스크에 기록한다. 트리가 이미 키로 정렬된 키-값 쌍을 유지하고 있기 때문에 이 작업은 효율적이다.
* 읽기 요청이 들어오면 먼저 tree에서 키를 찾는다. 없으면 최신 저장된 순으로 세그먼트에서 찾는다.
* 백그라운드로 세그먼트 파일의 병합과 컴팩션을 수행한다.

> 이렇게 해서 어떻게 데이터를 키로 정렬한다는 건지 잘 모르겠네..? 데이터가 여러 종류라면 어떡하려고?

그러나 여기에도 한 가지 문제가 있다.

tree가 인메모리이기 때문에 DB가 고장나면 tree에 있던 데이터가 유실된다. 이를 막기 위해 쓰기가 발생할때마다 디스크 상에 로그를 유지해야 한다. 이 로그들은 SS테이블로 기록되어 지고, 그 후 버려진다.

위와 같은 방식을 LSM 트리(Log-Structured Merge-Tree) 방식이라고 부르며, 이 원리를 기반으로 하는 저장소 엔진을 LSM 저장소 엔진이라고 부른다. 핵심 아이디어는 임의 접근 쓰기를 체계적으로 디스크에 순차쓰기로 바꾼 것이다.

세부적으로 더 들어가면, 성능을 올릴 수 있는 몇 가지 여지가 더 있다.

* LSM 트리 알고리즘은 DB에 존재하지 않는 키를 찾는 경우 느릴 수 있다. 가장 오래된 세그먼트 파일까지 거슬러 올라가야 하기 때문이다. 이걸 막기 위해 Bloom filter(키가 데이터베이스에 존재하지 않음을 알려주는 집합 근사 필터)를 사용한다.
* SS 테이블을 압축하고 병합하는 순서와 시기를 결정하기 위해 size-tiered 와 level-compaction 전략을 사용한다.

### B 트리

가장 널리 사용되는 색인 구조는 사실 B-tree다. B-tree는 설계 철학부터가 틀리기 때문에 LSM과 비교했을 때 키로 정렬된 키-값 쌍을 유지한다는 것 빼고는 대부분 다르다. 예를 들어 LSM은 가변적인 세그먼트로 나누고 항상 순차적으로 세그먼트를 기록하지만, B-tree는 전통적으로 4KB 크기의 블록이나 페이지로 나누고 한 번에 하나의 페이지에 Read/Write를 한다.

각 페이지는 포인터(메모리가 아니라 디스크에 존재하는)처럼 주소나 위치를 이용해 식별할 수 있다. 자세한 설명은 [여길](https://ko.wikipedia.org/wiki/B\_%ED%8A%B8%EB%A6%AC) 보면 좋다. n 개의 키를 가진 B 트리는 balanced 이기 때문에 깊이가 항상 log n 이라서, 검색에 O(log n)이 걸린다.

B-tree 는 기본적으로 새로운 데이터를 디스크 상의 페이지에 덮어쓴다. 이 때 DB 가 뻗어버리면 색인이 훼손되기 때문에 이를 방지하기 위해 write-ahead log(재실행 로그, WAL, redo log 라고도 함)라는 데이터 구조를 추가해 B-tree를 구현한다. 이 로그에는 변경사항이 기록되기 때문에, DB 복구시 B-tree를 다시 복원해낼 수 있다.

다중 스레드가 동시에 B-tree에 접근하는 경우는 어떨까? 이 경우에는 보통 가벼운 lock에 해당하는 래치(latch)로 데이터 구조를 보호한다.

또, B-tree 는 많은 최적화 기법을 가지고 있다.

* WAL 대신 copy-on-write scheme 을 써서 동시성 제어 문제를 한꺼번에 해결하기도 한다.
* 키를 압축해서 공간을 절약한다. 그러면 페이지에 더 많은 키가 채워지고 결과적으로 트리 깊이를 낮추어 성능이 올라간다.
* 물리적 디스크 상에 연속된 순서로 트리를 배치시킨다.
* 트리에 포인터를 추가한다. 리프 페이지가 양쪽 형제에 대한 참조를 가지면 상위 페이지에서 다시 아래로 스캔을 하지 않아도 된다.

### B 트리와 LSM 트리 비교

(필자의 경험적으로) LSM tree는 쓰기에서 더 빠른 반면 B-tree 는 읽기에서 더 빠르다. LSM tree의 읽기가 더 느린 이유는 각 컴팩션 단계에 있는 여러가지 데이터 구조와 SS테이블을 확인해야 하기 때문이다.

LSM 색인이나 B 트리 색인이나 반복된 컴팩션과 병합으로 인해 DB 쓰기 한 번에 디스크에 여러 번 쓰는 것을 유발시키는 데, 이를 쓰기 증폭(Write Amplification)이라 부른다. SSD의 경우 수명이 다할 때까지 블록 덮어쓰기 횟수가 제한되기 때문에 쓰기 증폭을 최대한 방어해야 한다.

만약 애플리케이션이 write가 매우 많다면 성능 병목이 DB가 디스크에 쓰는 속도 때문일 수도 있다.

LSM tree의 장점

* 보통 B-tree 보다 처리량을 높게 유지할 수 있다. LSM은 순차적으로 SS테이블 파일을 쓰는데, 이는 자기 하드드라이브에서 (임의쓰기보다 훨씬)더 빠른 속도를 낸다.
* 압축률이 더 좋아서 B-tree 보다 디스크에 더 적은 파일을 생성한다. B 트리는 파편화 때문에 쓰이지도 않는 공간이 중간 중간 비게 되는데, LSM은 주기적으로 SS테이블을 다시 기록해 파편화를 없앤다.

대다수의 SSD는 임의쓰기를 순차쓰기로 바꾸기 때문에 엔진이 순차쓰기로 쓴다고 해서 큰 성능 향상을 기대하긴 힘들지만, 쓰기 증폭의 방어와 파편화 감소는 성능에 분명한 영향을 준다.

LSM tree의 단점

* 컴팩션이 끝날때까지 읽기나 쓰기요청이 대기해야 하는 상황이 벌어진다.
* DB가 점점 커질수록 컴팩션에 할당되는 디스크의 대역폭이 늘어나고, 이는 곧 쓰기 처리량의 감소를 야기한다.

B tree는 반면 많은 작업부하에 지속적으로 좋은 성능을 제공한다.

### 기타 색인 구조

1.  색인 안에 값 저장하기

    보통 색인이 가리키는 곳은 원하는 데이터가 저장된 곳이다. 그러나 힙 파일(heap file) 접근 방식을 사용하는 경우 가리키는 곳에 데이터 대신 또 다시 포인터가 들어있어 어떤 상황에서는 데이터를 곧바로 색인에다가 저장하는 것이 바람직할 때가 있는데, 이를 클러스터드 인덱스(Clustered index)라고 한다. MySQL의 InnoDB는 테이블의 기본키가 언제나 클러스터드 인덱스고 보조 색인이 기본키를 참조한다.

    이에 대한 절충안으로 covering index, index with included column 라는 것들이 있는데, 데이터를 통으로 저장하는 것이 아니라 일부만 저장한다.
2.  다중 칼럼 색인

    하나의 키만 값에 대응 하는 경우를 지금까지 생각해봤는데, 성과 이름으로 검색하는 경우처럼 다중 칼럼에 색인해야 할 때가 있다. 가장 일반적인 유형은 결합 색인(Concatenated index) 이고 단순히 키 끼리 결합한다.

    단순 조회가 아니라 위도 경도 범위로 레스토랑을 검색해야 하는 경우, 위도와 경도를 단일 숫자로 표현하는 공간 채움 곡선함수를 이용해 변환하여 B tree 색인을 적용하기도 한다. (근데 보통은 이 경우 R tree라는 것을 더 많이 쓴다)
3.  전문 검색과 퍼지 색인

    정확한 데이터를 검색하는 경우가 아니라 유사한 값을 가져오는 검색처럼 애매모호한(fuzzy)에는 다른 기술이 필요하다. 여기엔 머신 러닝 기술이 도입되기도 한다.
4.  모든 것을 메모리에 보관

    데이터셋이 너무나 크지 않다면 인메모리 데이터베이스를 도입해볼 수도 있다.

## 트랜잭션 처리나 분석?

애플리케이션은 보통 일부 키에 대한 적은 양의 데이터를 조회한다. 이를 온라인 트랜잭션 처리(OLTP, Online Transaction Processing)라고 부른다.

그러나 요새는 OLTP 뿐만 아니라 데이터 분석에도 점점 더 많이 DB를 사용하기 시작했다. 이는 트랜잭션과 접근 패턴이 매우 다르다. 엄청난 양의 데이터를 스캔해 집계하고 통계를 낸다. 이를 온라인 분석처리(OLAP, Online Analytic Processing)라고 부른다.

### 데이터 웨어하우징

OLAP는 OLTP와 많은 부분에서 다르게 접근해야 한다. OLTP에서는 높은 가용성과 지연 시간이 적은 트랜잭션 처리를 기대하지만, OLAP에서는 대용량 데이터 셋의 적재 와 추출에 집중한다. 따라서 OLTP용 DB 와 OLAP용 DB는 분리하는 것이 일반적이며, OLAP 용 DB를 데이터 웨어하우스라고 한다. 이 데이터 웨어하우스에 데이터가 적재되기 위해서는 다음과 같은 과정을 거친다.

각 애플리케이션으로부터 데이터를 추출 - 변환 - 적재

이 과정을 ETL(Extract-Transform-Load)라고 한다. ETL이 된 데이터에 대한 쿼리에서는 지금까지 살펴봤던 인덱싱은 잘 작동하지 않는다. 이 쿼리를 위해서는 분석에 최적화된 저장소 엔진을 쓰는 것이 좋다.

### 분석용 스키마: 별 모양 스키마와 눈꽃송이 모양 스키마

OLTP나 OLAP용 DB는 모두 SQL 인터페이스를 지원하기 때문에 언뜻 별 다를 바 없어 보이지만, 시스템 내부적으로는 매우 다르다. 각각 트랜잭션 처리 혹은 분석 작업부하 하나에만 집중하여 처리한다.

star schema, 차원 모델링이라고 하는 방식을 많은 데이터 웨어하우스가 사용한다. 왜 이름이 별(star) 이냐면, 이벤트 소싱 방식에서 처럼 이벤트가 테이블에 저장되고, 이벤트 로우 안에서 외래키로 자세한 데이터를 살펴볼 수 있는 구조(다차원, 누가 - 언제 - 어디서 - 무엇을 - 어떻게 - 왜)이기 때문이다.

## 칼럼 지향 저장소

칼럼 지향 저장소는 모든 값을 하나의 로우에 함께 저장하지 않는 대신 각 칼럼별로 모든 값을 함께 저장한다. 이렇게 되면 쿼리에 필요한 컬럼만 디스크에서 읽어서 메모리에 올릴 수 있다.

### 칼럼 압축

필요한 칼럼만 읽어들이는 것 외에도 데이터를 압축하면 디스크 처리량을 늘릴 수 있다. bitmap encoding 같은 압축기법을 사용한다.

OLAP에서는 디스크로부터 메모리로 데이터를 가져오는 대역폭이 큰 병목이다. 벡터화 처리(Vectorized Processing)를 통해 디스크에서 CPU의 L1 캐시에 더 효율적으로 데이터를 연산하고 적재하여 이 병목을 줄일 수 있다.

### 칼럼 저장소의 순서 정렬

칼럼 저장소에서 로우가 저장되는 순서가 반드시 중요한 것은 아니나, 정렬된 순서로 데이터를 집어 넣게 되면 컬럼 압축에 도움이 된다.

뿐만 아니라, 복제 데이터를 서로 다른 방식으로 정렬해서 저장하면 쿼리를 처리할 때 가장 적합한 버전을 사용하도록 설계할 수도 있다.

### 칼럼 지향 저장소에 쓰기

칼럼 지향 저장소나 압축이나 정렬과 같은 최적화는 대부분의 분석가들이 하는 작업이 쓰기가 아닌 읽기이기 때문에 의미가 있지만, 이 모든 최적화는 쓰기를 느리게 만들 수밖에 없다.

LSM 에서 보았던 것처럼, 모든 쓰기는 먼저 인 메모리 저장소로 이동해 정렬된 구조에 추가하고 디스크에 쓸 준비를 한다면 좋은 해결책이 될 수 있다. B tree는 제자리 갱신(Update in place) 방식이기 때문에 여기선 적합하지 않다.

### 집계: 데이터 큐브와 구체적 뷰

쿼리가 자주 사용하는 COUNT나 SUM 같은 걸 미리 계산해서 캐싱해 놓으면 어떨까? 하는 아이디어에서 출발한 것이 구체화 집계(Materialized aggregate)이다.
